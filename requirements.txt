# College of Experts - Dependencies
#
# Primary Target: Windows with DirectML (AMD/Intel/NVIDIA)
# On Linux, replace `onnxruntime-genai-directml` with `onnxruntime-genai-cuda` or `onnxruntime-genai-rocm`

# --- Inference Engine (DirectML) ---
# Accelerates quantized models on consumer GPUs via DirectX 12
onnxruntime-genai-directml>=0.4.0

# --- Core Utilities ---
numpy>=1.26.0
requests>=2.31.0
psutil>=5.9.0
colorama>=0.4.6
Pillow>=10.0.0
tqdm>=4.66.0

# --- AI Frameworks ---
huggingface_hub>=0.23.0    # Model downloads
transformers>=4.40.0       # Tokenizers / fallback support
chromadb>=0.4.0            # Vector memory store
sentence-transformers>=2.7.0

# --- PyTorch (CPU Only) ---
# Used for utility functions and tokenizer support.
# Heavy inference is handled by onnxruntime-genai, so CPU torch is sufficient (and smaller).
torch>=2.2.0 --index-url https://download.pytorch.org/whl/cpu
